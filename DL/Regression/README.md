# ğŸ¦ TIL

[TensorFlow Regression Tutorial](https://www.tensorflow.org/tutorials/keras/regression)
## ì‹¤ìŠµ ëª©ì , ì•Œì•„ê°€ì•¼ í•˜ëŠ” ê²ƒ
* ì •í˜• ë°ì´í„° ì…ë ¥ì¸µ : `input_shape`
* ì •ê·œí™” ë ˆì´ì–´ ì‚¬ìš© â¡ï¸ ì§ì ‘ ì •ê·œí™” ê°€ëŠ¥
* ë¶„ë¥˜ì™€ ë‹¤ë¥¸ ì¶œë ¥ì¸µ
* ë¶„ë¥˜ì™€ ë‹¤ë¥¸ loss ì„¤ì •
* ì…ë ¥ë³€ìˆ˜ë¥¼ í•˜ë‚˜ë§Œ ì‚¬ìš©í–ˆì„ ë•Œë³´ë‹¤ ë” ì¢‹ì€ ì„±ëŠ¥
  * ë³€ìˆ˜ì˜ ê°œìˆ˜ë‘ ì„±ëŠ¥ì´ ë¹„ë¡€í•˜ì§„ ì•ŠìŒ
  * ê·¸ë ‡ì§€ë§Œ ì ì€ ë³€ìˆ˜ë¡œëŠ” ì˜ˆì¸¡ëª¨ë¸ì„ ì˜ ë§Œë“¤ê¸° ì–´ë ¤ì›€ 

## âœ… Regression
### - ì •ê·œí™” 

* `tensorflow` ì—ì„œ ì œê³µí•˜ëŠ” ì •ê·œí™” ì „ì²˜ë¦¬ ì½”ë“œ
```python
normalizer = tf.keras.layers.Normalization(axis=-1)
```
* ( 2ì°¨ì›, 1ì°¨ì› ) ì˜ ê²½ìš°
* ( axis=0 , axis=1 )
* ( axis=-2 , axis =-1 )

<br>

* 3ì°¨ì›ì˜ ê²½ìš°
* ( 3ì°¨, 2ì°¨, 1ì°¨ )
* ( axis=0, axis=1, axis=2)
* ( axis=-3, axis=-2 , axis =-1 )

<br>


```python
horsepower = np.array(train_features['Horsepower'])

horsepower_normalizer = layers.Normalization(input_shape=[1,], axis=None)
horsepower_normalizer.adapt(horsepower)


horsepower_model = tf.keras.Sequential([
    horsepower_normalizer,
    layers.Dense(units=1)
])

horsepower_model.summary()
```
* ì „ì²˜ë¦¬ ë ˆì´ì–´ë¥¼ ì¶”ê°€í•´ì„œ ëª¨ë¸ì— ì „ì²˜ë¦¬ ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥
* ì •ê·œí™” ë°©ë²•ì„ ëª°ë¼ë„ ì¶”ìƒí™”ëœ ê¸°ëŠ¥ ì´ìš©í•˜ì—¬ ì‰½ê²Œ ì •ê·œí™” ê°€ëŠ¥
* ì†ŒìŠ¤ì½”ë“œë¥¼ ì—´ì–´ë³´ê¸° ì „ê¹Œì§€ ì–´ë–¤ ê¸°ëŠ¥ì¸ì§€ ì•Œê¸° ì–´ë µë‹¤ëŠ” ë‹¨ì 
* `scikit-learn` ì˜ `pipeline` ê¸°ëŠ¥ê³¼ ìœ ì‚¬

<br>

### - ì¶œë ¥ì¸µ
* ë¶„ë¥˜ëŠ” í™œì„±í™” í•¨ìˆ˜ë¡œ ì†Œí”„íŠ¸ë§¥ìŠ¤, ì‹œê·¸ëª¨ì´ë“œë¥¼ ì‚¬ìš©í•œ ë°˜ë©´
* íšŒê·€ ì¶œë ¥ì¸µì˜ ê²½ìš° í•­ë“±í•¨ìˆ˜


<br>

### - compile

```python
horsepower_model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),
    loss='mean_absolute_error')
```
* `optimizer` ë¥¼ `"adam"` ìœ¼ë¡œ ì§€ì •í•˜ë©´ `learning_rate` ê¸°ë³¸ê°’ ì‚¬ìš©, ì§€ì • ë¶ˆê°€ëŠ¥

<br>

### - val_loss

```python
%%time
history = dnn_model.fit(
    train_features,
    train_labels,
    validation_split=0.2,
    verbose=0, epochs=100)
```

* `val_loss` : ê²€ì¦ ì†ì‹¤ ê°’
* `fit` ë‹¨ê³„ì—ì„œ `validation_split` ìœ¼ë¡œ ì§€ì •


<br>

### - flatten()
[ì°¸ê³  ìë£Œ](https://m.blog.naver.com/wideeyed/221533365486) <br>
[numpy tutorial](https://numpy.org/doc/stable/user/absolute_beginners.html)

```python
test_predictions = dnn_model.predict(test_features).flatten()
```
* 2ì°¨ì›ì„ 1ì°¨ì›ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ëŠ” í•¨ìˆ˜
* ì˜ˆì¸¡ê°’ì´ ê¸°ë³¸ì ìœ¼ë¡œ 2ì°¨ì›ìœ¼ë¡œ ë‚˜ì˜´ 


<br>

### - Earlystopping
```python
early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_mse', patience=100)

history = model.fit(x_train, y_train, epochs=1000, verbose=0, 
                    callbacks=[early_stop], validation_split=0.2)
```


